---
layout: default
title: High Performing IT Capabilities
ref: it-capabilities
lang: en
status: posted
sections: Archives
permalink: /high-performing-it-capabilities.html
---

## High Performing IT Capabilities

A DevOps Research and Assessment (DORA) [Quick Check of software delivery performance in ESDC and IITB](https://beta.devops-research.com/performance.html?leadtime=1&deployfreq=1&ttr=3&chgfail=4&industry=government) show that we are low performers for deployment frequency, lead time for changes, time to restore service and change fail rate.

The [State of DevOps Report](https://cloud.google.com/devops/state-of-devops/) has been published annually since 2014, as part of the DORA, a six-year research program that has validated a number of technical, process, measurement, and cultural [capabilities to drive higher software delivery and organizational performance](https://cloud.google.com/devops/#devops-capabilities).

IITB and ESDC must continuously improve these capabilities:

### Technical

- Version control
- Continuous integration
- Deployment automation
- Trunk-based development
- Test automation
- Architecture
- Empowering teams to choose tools
- Test data management
- Shifting left on security

### Process

- Team experimentation
- Streamlining change approval
- Customer feedback
- Visibility of work in the value stream
- Working in small batches

### Measurement

- Monitoring systems to inform business decisions
- Proactive failure notification
- Work in process limits
- Visual management capabilities

### Cultural

- Job satisfaction
- Westrum organizational culture
- Learning culture

### Assesment tool survey questions 
#### Section 3. DevOps measurement

##### Monitoring systems to inform business decisions

1. What is the purpose of the monitor and control phase in your team? (checkbox)
a. To monitor the project team
b. To measure the performance of the new process after the execution phase
c. To control the project team's performance
d. To monitor and control the planning and initiating phases

2.  What are the main steps involved in planning and implementing a monitoring protocol in your team: (checkbox)
a. Complete background tasks
b. Develop objectives
c. Design and implement management
d. Design the monitoring methodology
e. Implement monitoring as a pilot study
f. Implement monitoring
g. Report and use results
h. None of the above/not applicable 

3.  Which step in planning and implementing a monitoring protocol in your team takes the most time: 
a. Complete background tasks.
b. Develop objectives.
c. Design and implement management.
d. Design the monitoring methodology.
e. Implement monitoring as a pilot study.
f. Implement monitoring.
g. Report and use results.
h. None of the above/not applicable 

4. What instrumentation do you use to monitor applications running in production? 
a. Availability monitoring via pinging or synthetic transactions 
b. Performance monitoring of the servers and infrastructure 
c. Real user monitoring 
d. Multi-tier views of end-to-end transactions including processing and network combined 
e. None of the above/not applicable 

5. How fast your team reacts to alerts when the system approaches critical thresholds or goes down  
a. When the threshold reaches 25%
b. When the threshold reaches 50%
c. When the threshold reaches 75%
d. When the threshold reaches 85%
e. When the threshold reaches 95%

6. How is the monitoring process executed in your team?
a. Monitoring one or two areas at a time 
b. Monitoring the full software development

7. What method or tool do you use to display your data?

______________________________________________________

8. Which tool do you use to share collected data in your team?
a. Google docs
b. Sharepoint
c. Email
d. Office 365
e. Slack
f. None of the above/not applicable 

9. What has the most impact to make a business decision in your team?
a. Data from application performance monitoring tools 
b. Data from infrastructure monitoring tool
c. Outside perspective
d. Previous decision mistakes
f. Your gut instinct
g. None of the above/not applicable 

10. How usually  accurate and relevant  is the data to your team’s goal ?
a. Very Frequently 
b. Frequently
c. Occasionally 
d. Rarely 
e. Very Rarely 
f. Never

11. How often you felt guilty of seeing the data you wish was there instead of what’s really in front of you?  
a. Always 
b. Very Often
c. Sometimes
d. Rarely 
e. Never

##### Proactive failure notification

12. How often your team monitors the stability and security of your IT system
a. Very Frequently
b. Frequently 
c. Occasionally 
d. Rarely 
e. Very Rarely 
f. Never

13. How do you notify your team about failure alerts?
a. Via email
b. Via PR in Github
c. Via Slack
d. None of the above/not applicable 

14. How often do you  face the situation when your team finds out from customers that your application or service is down?
a. Always 
b. Very Often
c. Sometimes 
d. Rarely 
e. Never

15. What  indicators could have predicted the incident ?

_______________________________________________________

16. How long does it take to fix the problem?
a. More than I would like 
b. About right 
c. Less than I would like 

##### Work in process limits

17. Are people in your team often assigned to work on multiple tasks ? If yes , what is the main reason?
a. Too much work
b. Not enough people in the team
c. Not the right skill sets in the team
d. It usually doesn't happen

18. How often does your team discover invisible work when it is not expected ?
a. Almost always 
b. Often 
c. Sometimes 
d. Seldom 
e. Never

19. How visible is your work to the other teams and stakeholders?
a. Very good 
b. Good 
c. Fair 
d. Poor 
e. Very poor

20. How often project team meetings are held ?
a. Every day
b. Three times a week
c. Once a week
d. Randomly

###### Visual management capabilities

21. What type of tools do you use to manage the work at various stages of a process? 
a. Card walls
b. Storyboards
c. Kanban boards

22. How long does it take to complete a project backlog?
a. More than I would like 
b. About right 
c. Less than I would like 

23. How do you gather and measure feedback from users? 
a. Manual testing, user acceptance testing or general acceptance criteria 
b. Direct email/phone/listserv/web contact form, web meetings, or chat room 
c. In-product qualitative feedback (e.g. Send-a-Smile) and survey such as Net Promoter Score (NPS) 
d. Usage telemetry is gathered with real user monitoring at 100% sampling
e. None of the above/not applicable 
